#
# Copyright 2014 Internet2
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Grouper loader uses Grouper Configuration Overlays (documented on wiki)
# By default the configuration is read from grouper-loader.base.properties
# (which should not be edited), and the grouper-loader.properties overlays
# the base settings.  See the grouper-loader.base.properties for the possible
# settings that can be applied to the grouper.properties


########################################
## Config chaining hierarchy
########################################

# comma separated config files that override each other (files on the right override the left)
# each should start with file: or classpath:
# e.g. classpath:grouper-loader.example.properties, file:c:/something/myconfig.properties
loader.config.hierarchy = classpath:grouper-loader.base.properties, classpath:grouper-loader.properties

# seconds between checking to see if the config files are updated
loader.config.secondsBetweenUpdateChecks = 60


########################################
## General settings
########################################


# auto-add grouper loader types and attributes when grouper starts up if they are not there
loader.autoadd.typesAttributes = true

# if a transaction should be used when loading groups.  If not, then
# commits will happen as the group is loaded (and memory usage might be
# less intensive, and caching settings need to be set right)
loader.use.transactions = false

# if should use threads in the loader for add/remove member
loader.use.membershipThreads=true

# number of threads to use for each group job (not shared among jobs)
loader.membershipThreadPoolSize=10

# if should use threads in the loader for each group in a group of groups
loader.use.groupThreads=true

# number of threads to use for each list of groups job (not shared among jobs)
loader.groupThreadPoolSize=20

# if should use threads in incremental loader jobs
loader.incrementalThreads=true

# number of threads to use in incremental loader jobs (not shared among jobs)
loader.incrementalThreadPoolSize=10

# number of days to retain db logs in table grouperloader_log.  -1 is forever.  default is 7
loader.retain.db.logs.days=7

# number of days to retain db rows in grouper_change_log_entry.  -1 is forever.  default is 14
loader.retain.db.change_log_entry.days=14

# if daemon should remove old values which are multi-assigned if the attribute is single valued
loader.removeMultiAttributeValuesIfSingleValuedAttribute = true

# if daemon should remove old values which are multi-assigned if the attribute is single valued
loader.removeMultiAttributeValuesIfSingleValuedAttributeLogOnly = true

# if daemon should remove old assignments which are multi-assigned if the attribute is single assign
loader.removeMultiAttributeAssignIfSingleAssignAttribute = true

# if daemon should remove old assignments which are multi-assigned if the attribute is single assign
loader.removeMultiAttributeAssignIfSingleAssignAttributeLogOnly = true


############################################
## audit entries with no logged in user aren't really all that useful.  There is point in time data still.  So removing these shouldn't be a big deal
## default is remove these that are 5 years old.
############################################

# number of days to retain db rows in grouper_audit_entry with no logged in user (loader, gsh, etc).  -1 is forever.  suggested is 365 or five years: 1825.  Default is -1
loader.retain.db.audit_entry_no_logged_in_user.days=-1

############################################
## Some think its ok to remove all audit entries over 10 (or X) years, but will default this 
## to never since even at large institutions there aren't that many records.  
## These are audits for things people do on the UI or WS generally (as a different to records with no logged in user) 
############################################

# number of days to retain db rows in grouper_audit_entry.  -1 is forever.  suggested is -1 or ten years: 3650
loader.retain.db.audit_entry.days=-1

############################################
## After you delete an object in grouper, it is still in point in time.  So if you want to know who 
## was in a group a year ago, you need this info
## However, after some time it might be ok to let it go.  So the default is 5 years
############################################

# number of days to retain db rows for point in time deleted objects.  -1 is forever.  suggested is 365 or five years: 1825.  Default is -1
loader.retain.db.point_in_time_deleted_objects.days=-1

############################################
## This is optional.  You can automatically obliterate folders *directly in a parent folder* that are a certain age old  e.g. courses.
## so you could delete a term of courses 4 years old if you like.  Note, make sure the loader isn't going to recreate or you will get churn
## Note this can also delete the point in time data as well.
############################################

# number of days after a subfolder (directly in a parent folder) is created that it will be obliterated (deleted) 
# and point in time will be deleted too. 
# "courses" or "anotherLabel" are variables you make up in these examples
#loader.retain.db.folder.courses.days=1825
#loader.retain.db.folder.courses.parentFolderName=my:folder:for:courses
#loader.retain.db.folder.courses.deletePointInTime=true

#loader.retain.db.folder.anotherLabel.days=1825
#loader.retain.db.folder.anotherLabel.parentFolderName=my:folder:for:something
#loader.retain.db.folder.anotherLabel.deletePointInTime=false



# if you want queries which do not specify subject source to come from a certain
# source, specify here (improves performance so it doesnt search through all sources)
default.subject.source.id = 

#if using a sql table, and specifying the name like string, then should the group (in addition to memberships)
# be removed if not used anywhere else?
loader.sqlTable.likeString.removeGroupIfNotUsed = true

# if using a sql table, and specifying the name like string, then should the group be removed even when the group is member of some other group. 
# loader.sqlTable.likeString.removeGroupIfNotUsed has to be true for this to work
# https://bugs.internet2.edu/jira/browse/GRP-1132
loader.sqlTable.likeString.removeGroupIfMemberOfAnotherGroup = false

# by default the top folder for an ldap group of groups is the folder where the config group lives.
# set to false if you want to be able to provision groups to anywhere
loader.ldap.requireTopStemAsStemFromConfigGroup = true

# if you dont specify a groupNameExpression, groups will be loaded into this folder
# if this property doesnt exist, it will be groups:    if it is blank, then there is no top level folder
# e.g. loader:groups
loader.ldap.defaultGroupFolder = groups:

# Delimiter used in the example edu.internet2.middleware.grouper.app.loader.ldap.LdapResultsTransformationDelimitedValueExample
loader.ldap.resultsTransformationDelimitedValueExampleDelimiter = -

# Comma separated list of stems under which the display name changes in stems are allowed.
# eg: loader.allowStemDisplayNameChangesUnderStems=school:courses:english, school:faculty
loader.allowStemDisplayNameChangesUnderStems =

# fix include excludes on each run
loader.fixIncludeExcludes = false

#potentially delete groups that are no longer in the source system
loader.deleteGroupsNoLongerInSource = false


#potentially delete groups that are no longer in the source system
loader.deleteGroupsNoLongerInSource = false


######################################
# Fail-safe 1 - Each individual group
######################################

# if the loader should check to see too many users were removed, if so, then error out and
# wait for manual intervention
loader.failsafe.use = false

# if a group has a size less than this (default 200), then make changes including blanking it out 
loader.failsafe.minGroupSize = 200

# if a group with more members than the loader.failsafe.minGroupSize have more than this percent (default 30)  
# removed, then log it as error, fail the job, and don't actually remove the members 
# In order to run the job, an admin would need to change this param in the config, 
# and run the job manually, then change this config back 
loader.failsafe.maxPercentRemove = 30


############################################
# Fail-safe 2 - Group list - managed groups
############################################

# For group lists, if groupLikeString is specified, you can use this fail-safe to prevent too
# many groups from having their memberships cleared out because they are managed by the loader
# (i.e. match the groupLikeString) but don't have memberships in the group query.
loader.failsafe.groupList.managedGroups.use = false

# Only applicable if the number of managed groups (i.e. match the groupLikeString) that have
# members in Grouper before the loader starts is at least this amount.
loader.failsafe.groupList.managedGroups.minManagedGroups = 200

# If the group list meets the criteria above and the percentage of groups that are managed by
# the loader (i.e. match the groupLikeString) that currently have members in Grouper but 
# wouldn't after the job runs is greater than this percentage, then don't remove members,
# log it as an error and fail the job.  An admin would need to change this param in the config,
# and run the job manually, then change this config back.
loader.failsafe.groupList.managedGroups.maxPercentRemove = 30


#################################
## Performance enhancements
#################################

# if you want to bulk retrieve subjects to add/remove
loader.bulkLookupSubjects = true

#########################
# Unresolvables
#########################

#
# If there are unresolvables while loading a group from the source data, the job will still 
# have a result of SUCCESS unless the total membership count (with unresolvables) is 
# greater than or equal to minGroupSize and the percentage of unresolvables is greater than 
# the percent specified, in which case the result will be SUBJECT_PROBLEMS.
#
loader.unresolvables.minGroupSize = 200
loader.unresolvables.maxPercentForSuccess = 5


#################################
## DB connections
#################################
# specify the db connection with user, pass, url, and driver class
# the string after "db." is the name of the connection, and it should not have
# spaces or other special chars in it
#db.warehouse.user = mylogin
#note the password can be stored encrypted in an external file
#db.warehouse.pass = secret
#db.warehouse.url = jdbc:mysql://localhost:3306/grouper

## note: you probably dont have to enter a driver, it will detect from URL.  If it
## cant detect, then specify it here
#db.warehouse.driver = 

##optional pooling params, these will default to the grouper.hibernate(.base).properties pooling settings
#db.warehouse.c3p0.max_size = 100
#db.warehouse.c3p0.min_size = 0
##seconds
#db.warehouse.c3p0.timeout = 100
#db.warehouse.c3p0.max_statements = 0
#db.warehouse.c3p0.idle_test_period = 100
#db.warehouse.c3p0.acquire_increment = 1
#db.warehouse.c3p0.validate = false


# if the db connections should be pooled (this is new as of 2.3.0.patch)
grouperLoader.db.connections.pool = true

#################################
## LDAP connections
#################################
# specify the ldap connection with user, pass, url
# the string after "ldap." is the ID of the connection, and it should not have
# spaces or other special chars in it.  In this case is it "personLdap"

#note the URL should start with ldap: or ldaps: if it is SSL.  
#It should contain the server and port (optional if not default), and baseDn, 
#e.g. ldaps://ldapserver.school.edu:636/dc=school,dc=edu
#ldap.personLdap.url = ldaps://ldapserver.school.edu:636/dc=school,dc=edu

# load this ldaptive config file before the configs here.  load from classpath
#ldap.personLdap.configFileFromClasspath = ldap.personLdap.properties

#optional, if authenticated
#ldap.personLdap.user = uid=someapp,ou=people,dc=myschool,dc=edu

#optional, if authenticated, note the password can be stored encrypted in an external file
#ldap.personLdap.pass = secret

#optional, if you are using tls, set this to true.  Generally you will not be using an SSL URL to use TLS...
#ldap.personLdap.tls = false

#optional, if using sasl
#ldap.personLdap.saslAuthorizationId = 
#ldap.personLdap.saslRealm = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
#validateOnCheckout defaults to true if all other validate methods are false
#ldap.personLdap.batchSize = 
#ldap.personLdap.countLimit = 
#ldap.personLdap.timeLimit = 
#ldap.personLdap.timeout = 
#ldap.personLdap.minPoolSize = 
#ldap.personLdap.maxPoolSize = 
#ldap.personLdap.validateOnCheckIn = 
#ldap.personLdap.validateOnCheckOut = 
#ldap.personLdap.validatePeriodically = 
#ldap.personLdap.validateTimerPeriod = 
#ldap.personLdap.pruneTimerPeriod = 
# if there is a max size limit on ldap server, then this will retrieve results in pages
#ldap.personLdap.pagedResultsSize = 
# set to 'follow' if using AD and using paged results size and need this for some reason (generally you shouldnt)
#ldap.personLdap.referral = 
# validator setup, currently supports CompareLdapValidator and SearchValidator.  additional properties below for CompareLdapValidator.
#ldap.personLdap.validator = SearchValidator
#ldap.personLdap.validator = CompareLdapValidator
#ldap.personLdap.validatorCompareDn = ou=people,dc=example,dc=com
#ldap.personLdap.validatorCompareAttribute = ou
#ldap.personLdap.validatorCompareValue = people
# comma-delimited list of classes to process LDAP search results. Useful if AD returns a ranged attribute for large
# groups (e.g., member;range=0-1499); include the GrouperRangeEntryHandler to handle progressive fetching.
#ldap.personLdap.searchResultHandlers=org.ldaptive.handler.DnAttributeEntryHandler,edu.internet2.middleware.grouper.ldap.ldaptive.GrouperRangeEntryHandler
# comma-delimited list of result codes (org.ldaptive.ResultCode) to ignore, e.g. TIME_LIMIT_EXCEEDED, SIZE_LIMIT_EXCEEDED, PARTIAL_RESULTS
#ldap.personLdap.searchIgnoreResultCodes=SIZE_LIMIT_EXCEEDED

##################################
## LDAP loader settings
##################################

# el classes to add to the el context for the EL to calculate subejct ids or group names etc.  
# Comma-separated fully qualified classnamesm will be registered by the non-fully qualified
# uncapitalized classname.  So you register a.b.SomeClass, it will be available by variable: someClass
loader.ldap.el.classes = 

##################################
## Daemon logging
##################################

# When running the daemon log, do you want to log these various things?

# overall log for a job
daemon.log.logEnabled_overallLog = true

# subjob log for a job (e.g. if a job manages a lite of groups)
daemon.log.logEnabled_subjobLog = true

# groups being created or deleted
daemon.log.logEnabled_groupManagement = true

# memberships being created or deleted
daemon.log.logEnabled_membershipManagement = true

# if each logger map should have an id
daemon.log.logIdsEnabled = false



##################################
## Daily report
##################################
#quartz cron-like schedule for daily grouper report, the default is 7am every day: 0 0 7 * * ? 
#leave blank to disable this
daily.report.quartz.cron = 

#comma separated email addresses to email the daily report, e.g. a@b.c, b@c.d
daily.report.emailTo = 

#days on which usdu should run with daily report (comma separated)
#blank means run never.   e.g. to run on all days: monday, tuesday, wednesday, thursday, friday, saturday, sunday
daily.report.usdu.daysToRun = monday, tuesday, wednesday, thursday, friday, saturday, sunday

#days on which bad membership finder should run with daily report (comma separated)
#blank means run never.   e.g. to run on all days: monday, tuesday, wednesday, thursday, friday, saturday, sunday
daily.report.badMembership.daysToRun = monday, tuesday, wednesday, thursday, friday, saturday, sunday

#if you put a directory here, the daily reports will be saved there, and you can
#link up to a web service or store them or whatever.  e.g. /home/grouper/reports/
daily.report.saveInDirectory =

##################################
## enabled / disabled cron
##################################

#quartz cron-like schedule for enabled/disabled daemon.  Note, this has nothing to do with the changelog
#leave blank to disable this, the default is 12:01am, 11:01am, 3:01pm every day: 0 1 0,11,15 * * ? 
changeLog.enabledDisabled.quartz.cron = 0 1 0,11,15 * * ?

##################################
## grouper builtin messaging cleanup cron
##################################

#quartz cron-like schedule for grouper messaging daemon.
#leave blank to disable this, the default is every hour, 10 minutes after the hour 
#this daemon does cleanup on the builtin messaging table
changeLog.builtinMessagingDaemon.quartz.cron = 0 10 * * * ?

# after three days of not consuming messages, delete them, if -1, dont run this daemon
grouper.builtin.messaging.deleteAllMessagesMoreThanHoursOld = 72

# after three hours of having processed messages, delete them.  Note, if this is -1 just delete when marking processed
grouper.builtin.messaging.deleteProcessedMessagesMoreThanMinutesOld = 180





##################################
## Change log
##################################

# should the change log temp to change log daemon run?  Note, this should be true
changeLog.changeLogTempToChangeLog.enable = true

#quartz cron-like schedule for change log temp to change log daemon, the default is 50 seconds after every minute: 50 * * * * ?
changeLog.changeLogTempToChangeLog.quartz.cron = 

# The max number of changes to send to a change log consumer at one time
changeLog.changeLogConsumerBatchSize = 1000

# Should the change log include flattened memberships?  
changeLog.includeFlattenedMemberships = true

# Should the change log include flattened privileges?  
changeLog.includeFlattenedPrivileges = true

# Should the change log include roles that have had permission changes?  
changeLog.includeRolesWithPermissionChanges = false

# Should the change log include non-flattened (immediate and composite only) memberships?
changeLog.includeNonFlattenedMemberships = false

# Should the change log include non-flattened (immediate only) privileges?
changeLog.includeNonFlattenedPrivileges = false


##################################
## Change log consumers
##################################

# specify the consumers here.  specify the consumer name after the changeLog.consumer. part.  This example is "printTest"
# but it could be "myConsumerName" e.g. changeLog.consumer.myConsumerName.class
# the class must extend edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase
# note see Impl below

# changeLog.consumer.printTest.class = edu.internet2.middleware.grouper.changeLog.consumer.PrintTest

# the quartz cron is a cron-like string.  it defaults to every minute on the minute (since the temp to change log job runs
# at 10 seconds to each minute).  it defaults to this: 0 * * * * ?
# though it will stagger each one by 2 seconds.  You can leave this blank

# changeLog.consumer.printTest.quartzCron = 

# rules consumer, needed for some of the Grouper rule types to run (e.g. flattenedMembershipRemove, flattenedMembershipAdd)
changeLog.consumer.grouperRules.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.RuleConsumer
changeLog.consumer.grouperRules.quartzCron =

# consumer for syncing groups to other groupers
changeLog.consumer.syncGroups.class = edu.internet2.middleware.grouper.client.GroupSyncConsumer
changeLog.consumer.syncGroups.quartzCron =


##################################
## Change log consumers based in Impl
##################################
# Note, you might want to extend: edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBaseImpl
# this is a higher level change log consumer that does a lot of logic for you
# this class will fire certain events for groups and memberships based on tagged folders or groups
# Note, to use this make an attribute and assign it to (generally) folder(s) or some groups or whatever
# GSH:
# GrouperSession grouperSession = GrouperSession.startRootSession();
# AttributeDef provisioningMarkerAttributeDef = new AttributeDefSave(grouperSession).assignCreateParentStemsIfNotExist(true).assignName("attr:someAttrDef").assignToStem(true).assignToGroup(true).save();
# AttributeDefName provisioningMarkerAttributeName = new AttributeDefNameSave(grouperSession, provisioningMarkerAttributeDef).assignName("attr:provisioningMarker").save()
# Stem parentFolder = StemFinder.findByName(grouperSession, "some:folder", true);
# parentFolder.getAttributeDelegate().assignAttribute(provisioningMarkerAttributeName);


# changeLog.consumer.abc.class = edu.internet2.middleware.grouper.changeLog.consumer.PrintChangeLogConsumer
## note: this name matches the attribute name created in the example above
# changeLog.consumer.abc.syncAttributeName = attr:provisioningMarker
# changeLog.consumer.abc.quartzCron =
## defaults to true if not configured
# changeLog.consumer.abc.retryOnError = true



##################################
## PSP
##################################


# changeLog.consumer.psp.class = edu.internet2.middleware.psp.grouper.PspChangeLogConsumer

# http://www.quartz-scheduler.org/documentation/quartz-1.x/tutorials/crontrigger
# changeLog.consumer.psp.quartzCron = 0 * * * * ?

# To retry processing a change log entry if an error occurs, set retryOnError to true. Defaults to false.
# changeLog.consumer.psp.retryOnError = false

# To run full provisioning synchronizations periodically, provide the class name which provides a 'public void fullSync()' method.
# changeLog.psp.fullSync.class = edu.internet2.middleware.psp.grouper.PspChangeLogConsumer

# Schedule full synchronizations. Defaults to 5 am : 0 0 5 * * ?.
# changeLog.psp.fullSync.quartzCron = 0 0 5 * * ?

# Run a full synchronization job at startup. Defaults to false.
# changeLog.psp.fullSync.runAtStartup = false

# Omit diff responses from bulk response to conserve memory.
# changeLog.psp.fullSync.omitDiffResponses = true

# Omit sync responses from bulk response to conserve memory.
# changeLog.psp.fullSync.omitSyncResponses = true




###################################
## XMPP notifications 
## (note, uncomment the consumer class and cron above)
## this will get grouper ws getMembers rest lite xmp: 
## http://anonsvn.internet2.edu/cgi-bin/viewvc.cgi/i2mi/trunk/grouper-ws/grouper-ws/doc/samples/getMembers/WsSampleGetMembersRestLite_xml.txt?view=log
###################################

## general xmpp configuration
xmpp.server.host = jabber.school.edu
xmpp.server.port = 5222
xmpp.user = username
# note, pass can be in an external file with morphstring
xmpp.pass = 
xmpp.resource = grouperServer

###################################
## Rules config
###################################

# when the rules validations and daemons run.  Leave blank to not run
rules.quartz.cron = 0 0 7 * * ?

#####################################
## Messaging overall settings for daemon jobs
#####################################

# auto create built in queues, topics, privileges
loader.messaging.settings.autocreate.objects = true


#####################################
## Messaging listener using the messaging API
#####################################

# note, change "messagingListener" in key to be the name of the listener.  e.g. messaging.listener.myAzureListener.class
# extends edu.internet2.middleware.grouper.messaging.MessagingListenerBase
# note, routingKey property is valid only for rabbitmq. For other messaging systems, it is ignored.
# this listener will just print out messages: edu.internet2.middleware.grouper.messaging.MessagingListenerPrint
#
#messaging.listener.messagingListener.class = edu.internet2.middleware.grouper.messaging.MessagingListener
#messaging.listener.messagingListener.quartzCron = 0 * * * * ?
#messaging.listener.messagingListener.messagingSystemName = grouperBuiltinMessaging
#messaging.listener.messagingListener.queueName = abc
#messaging.listener.messagingListener.routingKey =
#messaging.listener.messagingListener.numberOfTriesPerIteration = 3
#messaging.listener.messagingListener.pollingTimeoutSeconds = 18
#messaging.listener.messagingListener.sleepSecondsInBetweenIterations = 0
#messaging.listener.messagingListener.maxMessagesToReceiveAtOnce = 20
# if there are 20 messages to receive at once, then do this 50 times per call max
#messaging.listener.messagingListener.maxOuterLoops = 50

#####################################
## Messaging listener using the change log consumer API
#####################################

# note, change "messagingListenerChangeLogConsumer" in key to be the name of the listener.  e.g. messaging.listener.myAzureListener.class
#
# keep this class to be MessagingListenerToChangeLogConsumer
#messaging.listener.messagingListenerChangeLogConsumer.class = edu.internet2.middleware.grouper.messaging.MessagingListenerToChangeLogConsumer
#messaging.listener.messagingListenerChangeLogConsumer.changeLogConsumerClass = edu.internet2.middleware.grouper.messaging.SomethingExtendsChangeLogConsumerBase
#messaging.listener.messagingListenerChangeLogConsumer.quartzCron = 0 * * * * ?
#messaging.listener.messagingListenerChangeLogConsumer.messagingSystemName = grouperBuiltinMessaging
#messaging.listener.messagingListenerChangeLogConsumer.queueName = abc
#messaging.listener.messagingListenerChangeLogConsumer.numberOfTriesPerIteration = 3
#messaging.listener.messagingListenerChangeLogConsumer.pollingTimeoutSeconds = 18
#messaging.listener.messagingListenerChangeLogConsumer.sleepSecondsInBetweenIterations = 0
#messaging.listener.messagingListenerChangeLogConsumer.maxMessagesToReceiveAtOnce = 20
# if there are 20 messages to receive at once, then do this 50 times per call max
#messaging.listener.messagingListenerChangeLogConsumer.maxOuterLoops = 50





#####################################
## Messaging integration with change log, send change log entries to a messaging system
#####################################
# note, change "messaging" in key to be the name of the consumer.  e.g. changeLog.consumer.myAzureConsumer.class
# note, routingKey property is valid only for rabbitmq. For other messaging systems, it is ignored.
#changeLog.consumer.messaging.class = edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerToMessage
#changeLog.consumer.messaging.quartzCron = 0 * * * * ?
#changeLog.consumer.messaging.messagingSystemName = grouperBuiltinMessaging
#changeLog.consumer.messaging.routingKey = 
# queue or topic
#changeLog.consumer.messaging.messageQueueType = queue
#changeLog.consumer.messaging.queueOrTopicName = abc


#####################################
## Messaging integration with ESB, send change log entries to a messaging system
#####################################
# note, change "messagingEsb" in key to be the name of the consumer.  e.g. changeLog.consumer.myAzureConsumer.class
# note, routingKey property is valid only for rabbitmq. For other messaging systems, it is ignored.
#changeLog.consumer.messagingEsb.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer
#changeLog.consumer.messagingEsb.quartzCron = 0 * * * * ?
#changeLog.consumer.messagingEsb.elfilter = event.eventType eq 'GROUP_DELETE' || event.eventType eq 'GROUP_ADD' || event.eventType eq 'MEMBERSHIP_DELETE' || event.eventType eq 'MEMBERSHIP_ADD'
#changeLog.consumer.messagingEsb.publisher.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbMessagingPublisher
#changeLog.consumer.messagingEsb.publisher.messagingSystemName = grouperBuiltinMessaging
#changeLog.consumer.messagingEsb.publisher.routingKey = 
# queue or topic
#changeLog.consumer.messagingEsb.messageQueueType = queue
#changeLog.consumer.messagingEsb.publisher.queueOrTopicName = abc


#####################################
## ESB integration
#####################################

#changeLog.consumer.awsJira.quartzCron = 0/15 * * * * ?
#changeLog.consumer.awsJira.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer
#changeLog.consumer.awsJira.elfilter = event.eventType eq 'MEMBERSHIP_ADD' || event.eventType eq 'MEMBERSHIP_ADD'
#changeLog.consumer.awsJira.noSensitiveData = true
## if you want to encrypt messages, set this to an implementation of edu.internet2.middleware.grouperClient.encryption.GcEncryptionInterface
#changeLog.consumer.awsJira.encryptionImplementation = edu.internet2.middleware.grouperClient.encryption.GcSymmetricEncryptAesCbcPkcs5Padding
## this is a key or could be encrypted in a file as well like other passwords
## generate a key with: java -cp grouperClient.jar edu.internet2.middleware.grouperClient.encryption.GcGenerateKey 
#changeLog.consumer.awsJira.encryptionKey = abc123
## if you dont want to send the first 4 of the sha hash base 64 of the secret
#changeLog.consumer.awsJira.dontSendShaBase64secretFirst4 = abc123
#changeLog.consumer.awsJira.publisher.class = edu.internet2.middleware.grouperAwsChangelog.GrouperAwsEsbPublisher
#changeLog.consumer.awsJira.publisher.awsAccessKey = ABCXYZ
#changeLog.consumer.awsJira.publisher.awsSecretKey = 123REWQ
#changeLog.consumer.awsJira.publisher.awsRegion = US_EAST_1
#changeLog.consumer.awsJira.publisher.awsSnsTopicArn = arn:aws:sns:us-east-1:123:name

#changeLog.consumer.xmppTest.quartzCron = 
#changeLog.consumer.xmppTest.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer
#changeLog.consumer.xmppTest.elfilter = event.eventType eq 'GROUP_DELETE' || event.eventType eq 'GROUP_ADD' || event.eventType eq 'MEMBERSHIP_DELETE' || event.eventType eq 'MEMBERSHIP_ADD'
#changeLog.consumer.xmppTest.publisher.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbXmppPublisher
#changeLog.consumer.xmppTest.publisher.server = jabber.school.edu
#changeLog.consumer.xmppTest.publisher.port = 5222
#changeLog.consumer.xmppTest.publisher.username = jabberuser
#changeLog.consumer.xmppTest.publisher.password = /home/whatever/pass/jabberuserEncrypted.pass
#changeLog.consumer.xmppTest.publisher.recipient = system1@school.edu
#changeLog.consumer.xmppTest.publisher.addSubjectAttributes = NETID
##note, on the content type header, activemq might need: application/x-www-form-urlencoded
#changeLog.consumer.xmppTest.publisher.contentTypeHeader = application/json; charset=utf-8
##note, on the stringRequestEntityPrefix, activemq might need: data=
#changeLog.consumer.xmppTest.publisher.stringRequestEntityPrefix = 
##note, on the stringRequestEntityContentType, activemq might need: application/x-www-form-urlencoded
#changeLog.consumer.xmppTest.publisher.stringRequestEntityContentType = application/json


################################
## Other jobs
## 
## Configure other jobs.
## "jobName" is the name of your job.
## Class must implement org.quartz.Job.
## Priority is optional
##
## For jobs that run by default, you can disable them by setting an empty quartz cron in grouper-loader.properties.
################################

##################################
## Find and fix bad memberships
##################################
otherJob.findBadMemberships.class = edu.internet2.middleware.grouper.misc.FindBadMembershipsDaemon
otherJob.findBadMemberships.quartzCron = 0 0 1 * * ?

##################################
## Find and fix scheduler issues
##################################
otherJob.schedulerCheckDaemon.class = edu.internet2.middleware.grouper.app.loader.GrouperDaemonSchedulerCheck
otherJob.schedulerCheckDaemon.quartzCron = 25 0/30 * * * ?

#####################################
## Atttestation Job
#####################################
otherJob.attestationDaemon.class = edu.internet2.middleware.grouper.app.attestation.GrouperAttestationJob
otherJob.attestationDaemon.quartzCron = 0 0 1 * * ?

#####################################
## Deprovisioning Job
#####################################
otherJob.deprovisioningDaemon.class = edu.internet2.middleware.grouper.app.deprovisioning.GrouperDeprovisioningJob
otherJob.deprovisioningDaemon.quartzCron = 0 0 2 * * ?

#####################################
## Object Type Job
#####################################
otherJob.grouperObjectTypeDaemon.class = edu.internet2.middleware.grouper.app.grouperTypes.GrouperObjectTypesJob
otherJob.grouperObjectTypeDaemon.quartzCron = 0 0 3 * * ?

#####################################
## Message to WS Daemon Job
#####################################
#otherJob.messageConsumerDaemon.class = edu.internet2.middleware.grouper.app.messaging.MessageConsumerDaemon
#otherJob.messageConsumerDaemon.quartzCron = 0 * * ? * *

# there can be multiple entries, "wsMessagingBridge" is the name of this one, change that for each config section
 
# the messaging system name must correspond to a messaging system in the grouper.client.properties
# grouper.messaging.wsMessagingBridge.messagingSystemName = rabbitMqMessaging
 
# the queue or topic to check
#grouper.messaging.wsMessagingBridge.queueOrTopicName = sampleWsMessagingQueue

# routingKey is only valid for rabbitmq; for others, it's ignored
#grouper.messaging.wsMessagingBridge.routingKey = 
 
# if this is a "queue" or "topic", generally it will be queue
#grouper.messaging.wsMessagingBridge.messageQueueType = queue
 
# the source id of the source of the user to act as
#grouper.messaging.wsMessagingBridge.actAsSubjectSourceId = g:isa
 
# the subject id of the user to act as
#grouper.messaging.wsMessagingBridge.actAsSubjectId = GrouperSystem
 
# the long polling seconds, listen to the queue for this many seconds for messages
#grouper.messaging.wsMessagingBridge.longPollingSeconds = 20

# grouper ws url
#grouper.messaging.wsMessagingBridge.ws.url =

# grouper ws username
#grouper.messaging.wsMessagingBridge.ws.username = 

# grouper ws password
#grouper.messaging.wsMessagingBridge.ws.password = 

#####################################################
## TIER Instrumentation daemon - send stats to TIER.
#####################################################
# otherJob.tierInstrumentationDaemon.class = edu.internet2.middleware.grouper.instrumentation.TierInstrumentationDaemon
# otherJob.tierInstrumentationDaemon.quartzCron = 0 0 2 * * ?
otherJob.tierInstrumentationDaemon.discoveryUrl = https://id.internet2.edu/ti/jrd/collector

# optionally exclude counts of recent changes (memberships, privileges, etc)
otherJob.tierInstrumentationDaemon.exclude.transactionCounts = false

# optionally exclude counts of total registry size (memberships, privileges, etc)
otherJob.tierInstrumentationDaemon.exclude.registryCounts = false

# optionally exclude which patches you've installed
otherJob.tierInstrumentationDaemon.exclude.patchesInstalled = false

# optionally exclude grouper version
otherJob.tierInstrumentationDaemon.exclude.version = false

# optionally exclude data about each instance (host, engine type, various counts, etc)
otherJob.tierInstrumentationDaemon.exclude.instanceData = false


############################
## Incremental loader jobs
############################
# otherJob.incrementalLoader1.class = edu.internet2.middleware.grouper.app.loader.GrouperLoaderIncrementalJob
# otherJob.incrementalLoader1.quartzCron = 0 * * * * ?
# otherJob.incrementalLoader1.databaseName=warehouse
# otherJob.incrementalLoader1.tableName=myincrementaltable
#
# If there are more than this many changes for a single loader job, then invoke the full sync instead.  This could improve performance but also handle fail safe which isn't part of the incremental sync.
# otherJob.incrementalLoader1.fullSyncThreshold=100

# must implement the java interface: org.quartz.Job
# see edu.internet2.middleware.grouper.app.loader.GrouperLoaderIncrementalJob as an example
# otherJob.jobName.class = 
# otherJob.jobName.quartzCron = 
# otherJob.jobName.priority =


#############
## Quartz
#############
org.quartz.scheduler.instanceName = DefaultQuartzScheduler
org.quartz.scheduler.instanceId = AUTO
org.quartz.scheduler.rmi.export = false
org.quartz.scheduler.rmi.proxy = false
org.quartz.scheduler.wrapJobExecutionInUserTransaction = false
org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool
org.quartz.threadPool.threadCount = 10
org.quartz.threadPool.threadPriority = 5
org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true
org.quartz.jobStore.misfireThreshold = 60000

org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX
org.quartz.jobStore.dataSource = myDS
org.quartz.jobStore.tablePrefix = grouper_QZ_
org.quartz.jobStore.isClustered = true
org.quartz.jobStore.clusterCheckinInterval = 20000

org.quartz.dataSource.myDS.maxConnections = 5
org.quartz.dataSource.myDS.validationQuery = select id from grouper_ddl

# automatically determined but can override
org.quartz.jobStore.driverDelegateClass =

# automatically determined based on hibernate configuration but can override
org.quartz.dataSource.myDS.driver =
org.quartz.dataSource.myDS.URL =
org.quartz.dataSource.myDS.user =
org.quartz.dataSource.myDS.password =


# Quartz seems to have issues where sometimes a job is running twice at the same time, usually after a misfire.
# We have our own check to make sure jobs don't overlap based on data in the grouper_loader_log table if a job's status is STARTED.
# However, if the daemon is killed, it may be stuck on the STARTED state until the row is deleted.  So we'll consider a job's
# STARTED state to be invalid if it hasn't been updated in the number of seconds below.
loader.assumeJobKilledIfNoUpdateInSeconds=300
